{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNIK.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7QP48bAaMgR"
      },
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QvW9GHkhUnN",
        "outputId": "4cc76b77-3e2f-40d2-e83b-4369c2ca6d41"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s86-bOvUbxCU"
      },
      "source": [
        "def conv_branch_init(conv, branches):\n",
        "    weight = conv.weight\n",
        "    n = weight.size(0)\n",
        "    k1 = weight.size(1)\n",
        "    k2 = weight.size(2)\n",
        "    nn.init.normal_(weight, 0, math.sqrt(2. / (n * k1 * k2 * branches)))\n",
        "    nn.init.constant_(conv.bias, 0)\n",
        "\n",
        "\n",
        "def conv_init(conv):\n",
        "    nn.init.kaiming_normal_(conv.weight, mode='fan_out')\n",
        "    nn.init.constant_(conv.bias, 0)\n",
        "\n",
        "\n",
        "def bn_init(bn, scale):\n",
        "    nn.init.constant_(bn.weight, scale)\n",
        "    nn.init.constant_(bn.bias, 0)\n",
        "\n",
        "class UnfoldTemporalWindows(nn.Module):\n",
        "    def __init__(self, window_size, window_stride=1, window_dilation=1):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.window_stride = window_stride\n",
        "        self.window_dilation = window_dilation\n",
        "\n",
        "        self.padding = (window_size + (window_size-1) * (window_dilation-1) - 1) // 2\n",
        "        self.unfold = nn.Unfold(kernel_size=(self.window_size, 1),\n",
        "                                dilation=(self.window_dilation, 1),\n",
        "                                stride=(self.window_stride, 1),\n",
        "                                padding=(self.padding, 0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input shape: (N,C,T,V), out: (N,C,T,V*tau)\n",
        "        N, C, T, V = x.shape\n",
        "        x = self.unfold(x)\n",
        "        x = x.view(N, C, self.window_size, -1, V).permute(0,1,3,2,4).contiguous()\n",
        "        x = x.view(N, C, -1, self.window_size * V)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Temporal unit\n",
        "class T_LSU(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, dilation=1, autopad=True):\n",
        "        super(T_LSU, self).__init__()\n",
        "        if autopad:\n",
        "            pad = int(( kernel_size - 1) * dilation // 2)\n",
        "        else:\n",
        "            pad = 0\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(kernel_size, 1), padding=(pad, 0),\n",
        "                              stride=(stride, 1), dilation=(dilation, 1))\n",
        "   \n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        conv_init(self.conv)\n",
        "        bn_init(self.bn, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(self.conv(x))\n",
        "        return x\n",
        "\n",
        "# Spatial unit\n",
        "class S_LSU(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_joints, tau=1, num_heads=8, coff_embedding=4, bias=True):\n",
        "        super(S_LSU, self).__init__()\n",
        "        inter_channels = out_channels // coff_embedding\n",
        "        self.inter_c = inter_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.tau = tau\n",
        "        self.num_heads = num_heads\n",
        "        self.DepM = nn.Parameter(torch.Tensor(num_heads, num_joints*tau, num_joints*tau))\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.Tensor(num_joints*tau))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "        \n",
        "        # Temporal window        \n",
        "        if tau != 1:\n",
        "            self.tw = UnfoldTemporalWindows(window_size=tau, window_stride=1, window_dilation=1)\n",
        "            self.out_conv = nn.Conv3d(out_channels, out_channels, kernel_size=(1, tau, 1))\n",
        "            self.out_bn = nn.BatchNorm2d(out_channels)\n",
        "        # Attention\n",
        "        self.conv_a = nn.ModuleList()\n",
        "        self.conv_b = nn.ModuleList()\n",
        "        self.conv_d = nn.ModuleList()\n",
        "        for i in range(self.num_heads):\n",
        "            self.conv_a.append(nn.Conv2d(in_channels, inter_channels, 1))\n",
        "            self.conv_b.append(nn.Conv2d(in_channels, inter_channels, 1))\n",
        "            self.conv_d.append(nn.Conv2d(in_channels, out_channels, 1))\n",
        "\n",
        "        if in_channels != out_channels:\n",
        "            self.down = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 1),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "        else:\n",
        "            self.down = lambda x: x\n",
        "\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.soft = nn.Softmax(-2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                conv_init(m)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                bn_init(m, 1)\n",
        "        bn_init(self.bn, 1e-6)\n",
        "        for i in range(self.num_heads):\n",
        "            conv_branch_init(self.conv_d[i], self.num_heads)\n",
        "            \n",
        "            \n",
        "    def reset_parameters(self) -> None:\n",
        "        nn.init.kaiming_uniform_(self.DepM, a=math.sqrt(5))\n",
        "        if self.bias is not None:\n",
        "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.DepM)\n",
        "            bound = 1 / math.sqrt(fan_in)\n",
        "            nn.init.uniform_(self.bias, -bound, bound)\n",
        "            \n",
        "            \n",
        "    def forward(self, x):\n",
        "        if self.tau != 1:\n",
        "            x = self.tw(x)\n",
        "        N, C, T, V = x.size()\n",
        "     \n",
        "        W = self.DepM\n",
        "        B = self.bias\n",
        "        y = None\n",
        "        for i in range(self.num_heads):\n",
        "           \n",
        "            A1 = self.conv_a[i](x).permute(0, 3, 1, 2).contiguous().view(N, V, self.inter_c * T)\n",
        "            A2 = self.conv_b[i](x).view(N, self.inter_c * T, V)\n",
        "            A1 = self.soft(torch.matmul(A1, A2) / A1.size(-1))  # N tV tV\n",
        "            \n",
        "            A1 = W[i] + A1\n",
        "            A2 = x.view(N, C * T, V)\n",
        "            z = self.conv_d[i]((torch.matmul(A2, A1)).view(N, C, T, V))\n",
        "            y = z + y if y is not None else z\n",
        "\n",
        "        y = self.bn(y)\n",
        "        y += self.down(x)\n",
        "        \n",
        "        if self.tau == 1:\n",
        "            return self.relu(y).view(N, -1, T, V)\n",
        "        else:\n",
        "            y = self.relu(y)\n",
        "            y = y.view(N, self.out_channels, -1, self.tau, V // self.tau)\n",
        "            y = self.out_conv(y).squeeze(dim=3)\n",
        "            y = self.out_bn(y)\n",
        "            return y\n",
        "\n",
        "\n",
        "\n",
        "class ST_block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_joints=20, tau=1, num_heads=3, stride=1, dilation=1, autopad=True, residual=True):\n",
        "        super(ST_block, self).__init__()\n",
        "        self.s_unit = S_LSU(in_channels, out_channels, num_joints, tau, num_heads)\n",
        "        self.t_unit = T_LSU(out_channels, out_channels, stride=stride, dilation=dilation, autopad=autopad)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.pad = 0\n",
        "        if not autopad:\n",
        "            self.pad = (tau - 1) * dilation // 2\n",
        "\n",
        "        if not residual:\n",
        "            self.residual = lambda x: 0\n",
        "\n",
        "        elif (in_channels == out_channels) and (stride == 1):\n",
        "            self.residual = lambda x: x\n",
        "\n",
        "        else:\n",
        "            self.residual = T_LSU(in_channels, out_channels, kernel_size=1, stride=stride)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.t_unit(self.s_unit(x)) + self.residual(x[:, :, self.pad : x.shape[2] - self.pad, :])\n",
        "        return self.relu(x)\n",
        "\n",
        "\n",
        "class UNIK(nn.Module):\n",
        "    def __init__(self, num_class=49, num_joints=20, tau=3, num_heads=3, in_channels=3):\n",
        "        super(UNIK, self).__init__()\n",
        "\n",
        "        \n",
        "        self.tau = tau\n",
        "        self.data_bn = nn.BatchNorm1d(in_channels * num_joints)\n",
        "\n",
        "        self.l1 = ST_block(in_channels, 32, num_joints, tau, residual=False)\n",
        "        \n",
        "        self.l2 = ST_block(32, 32, num_joints, tau, num_heads, dilation=1) #3\n",
        "        self.l3 = ST_block(32, 32, num_joints, tau, num_heads, dilation=1)   #3\n",
        "        \n",
        "        self.l4 = ST_block(32, 64, num_joints, tau, num_heads, stride=2)\n",
        "        self.l5 = ST_block(64, 64, num_joints, tau, num_heads)\n",
        "        \n",
        "        self.l6 = ST_block(64, 128, num_joints, tau, num_heads, stride=2)\n",
        "        self.l7 = ST_block(128, 128, num_joints, tau, num_heads)\n",
        "\n",
        "        self.fc = nn.Linear(128, num_class)\n",
        "        nn.init.normal_(self.fc.weight, 0, math.sqrt(2. / num_class))\n",
        "        bn_init(self.data_bn, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C, V, T = x.size()\n",
        "        x = x.permute(0,2,1,3).contiguous().view(N,V*C,T)\n",
        "        x = self.data_bn(x)\n",
        "        x = x.view(N,V,C,T).permute(0,2,3,1).contiguous().view(N,C,T,V)\n",
        "\n",
        "        x = self.l1(x)\n",
        "        x = self.l2(x)\n",
        "        x = self.l3(x)\n",
        "        x = self.l4(x)\n",
        "        x = self.l5(x)\n",
        "        x = self.l6(x)\n",
        "        x = self.l7(x)\n",
        "\n",
        "\n",
        "        c_new = x.size(1)\n",
        "        x=x.view(N,c_new,-1)\n",
        "        x = x.mean(2)\n",
        "\n",
        "        return self.fc(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaphY4zubAp3"
      },
      "source": [
        "class GCNDataset(Dataset):\n",
        "    def __init__(self,filename,hasLabel=True):\n",
        "        self.df = pd.read_csv(filename,header=None)\n",
        "        self.length = len(self.df)\n",
        "        if hasLabel:\n",
        "            #self.df['freq']=1./self.df.groupby(961)[961].transform('count')\n",
        "            #self.df = self.df.sample(frac=1,weights=self.df.freq).reset_index(drop=True)\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
        "            self.X = torch.tensor(self.df.iloc[:,1:-1].values.astype('float32'))\n",
        "            # N, C, V, T\n",
        "            self.X = self.X.reshape((self.length ,16, 20, 3)).permute(0,3,2,1).contiguous()\n",
        "            labels = self.df.iloc[:,-1].values.astype('int32')-1\n",
        "            self.Y = np.zeros((labels.size, labels.max()+1))\n",
        "            self.Y[np.arange(labels.size),labels] = 1\n",
        "        else:\n",
        "            self.X = torch.tensor(self.df.iloc[:,1:].values.astype('float32'))\n",
        "            self.X = self.X.reshape((self.length ,16, 20, 3)).permute(0,3,2,1).contiguous()\n",
        "            self.Y = np.zeros((self.length,49))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self,index):\n",
        "        x = self.X[index]\n",
        "        y = self.Y[index]\n",
        "        return x, y "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9yV7b5ibLaE"
      },
      "source": [
        "root_path = \"drive/MyDrive/SML/\"\n",
        "train_set = GCNDataset(filename=root_path+\"training_set.csv\")\n",
        "val_set = GCNDataset(filename=root_path+\"val_set.csv\")\n",
        "test_set = GCNDataset(filename=root_path+\"test.csv\",hasLabel=False)\n",
        "train_loader = DataLoader(train_set,batch_size=64)\n",
        "val_loader = DataLoader(val_set,batch_size=64)\n",
        "test_loader = DataLoader(test_set,batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2fXqnK7c_Yc",
        "outputId": "b068dbf3-f172-42a5-ca0c-f26d20f68fed"
      },
      "source": [
        "net = UNIK()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "opti = optim.Adam(net.parameters(), lr = 2e-5)\n",
        "\n",
        "gpu = 0 #gpu ID\n",
        "net.cuda(gpu)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nkJPZ0n9ds9U",
        "outputId": "d1262d09-074a-441b-c00d-dabe8ab11325"
      },
      "source": [
        "def accuracy(logit,target):\n",
        "    a=(torch.argmax(logit,dim=1)==torch.argmax(target,dim=1)).sum()\n",
        "    return a\n",
        "\n",
        "def evaluate(model, criterion, dataloader, gpu):\n",
        "    model.eval()\n",
        "    acc = 0\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for i,(x,y) in enumerate(dataloader):\n",
        "            x,y = x.cuda(gpu), y.cuda(gpu)\n",
        "            logits = model(x)\n",
        "            acc+= accuracy(logits, y)\n",
        "            count += 64\n",
        "\n",
        "    return acc / count\n",
        "\n",
        "def train():\n",
        "    best_acc=0.44\n",
        "    best_epoch = 0\n",
        "    for epoch in range(200):\n",
        "        print(\"epoch:\",epoch)\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for i, (x,y) in enumerate(train_loader):\n",
        "            opti.zero_grad()\n",
        "            x,y=x.cuda(gpu),y.cuda(gpu)\n",
        "            opti.zero_grad()\n",
        "            logit = net(x)\n",
        "            loss = criterion(logit,y)\n",
        "            loss.backward()\n",
        "            opti.step()\n",
        "            correct+=accuracy(logit,y)\n",
        "            total+=64\n",
        "        print(\"train acc:\",correct/total)\n",
        "\n",
        "        dev_acc = evaluate(net, criterion, val_loader, gpu)\n",
        "        if dev_acc>best_acc:\n",
        "            best_acc=dev_acc\n",
        "            torch.save(net.state_dict(), root_path+'UNIK_best.pkl')\n",
        "            torch.save(opti.state_dict(), root_path+\"UNIK_best_optim.pkl\")\n",
        "        print(\"dev_acc:\",dev_acc)\n",
        "train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0\n",
            "train acc: tensor(0.0090, device='cuda:0')\n",
            "dev_acc: tensor(0.0073, device='cuda:0')\n",
            "epoch: 1\n",
            "train acc: tensor(0.0695, device='cuda:0')\n",
            "dev_acc: tensor(0.1250, device='cuda:0')\n",
            "epoch: 2\n",
            "train acc: tensor(0.1698, device='cuda:0')\n",
            "dev_acc: tensor(0.1885, device='cuda:0')\n",
            "epoch: 3\n",
            "train acc: tensor(0.2019, device='cuda:0')\n",
            "dev_acc: tensor(0.2063, device='cuda:0')\n",
            "epoch: 4\n",
            "train acc: tensor(0.2213, device='cuda:0')\n",
            "dev_acc: tensor(0.2198, device='cuda:0')\n",
            "epoch: 5\n",
            "train acc: tensor(0.2350, device='cuda:0')\n",
            "dev_acc: tensor(0.2286, device='cuda:0')\n",
            "epoch: 6\n",
            "train acc: tensor(0.2436, device='cuda:0')\n",
            "dev_acc: tensor(0.2344, device='cuda:0')\n",
            "epoch: 7\n",
            "train acc: tensor(0.2524, device='cuda:0')\n",
            "dev_acc: tensor(0.2401, device='cuda:0')\n",
            "epoch: 8\n",
            "train acc: tensor(0.2613, device='cuda:0')\n",
            "dev_acc: tensor(0.2464, device='cuda:0')\n",
            "epoch: 9\n",
            "train acc: tensor(0.2677, device='cuda:0')\n",
            "dev_acc: tensor(0.2500, device='cuda:0')\n",
            "epoch: 10\n",
            "train acc: tensor(0.2761, device='cuda:0')\n",
            "dev_acc: tensor(0.2552, device='cuda:0')\n",
            "epoch: 11\n",
            "train acc: tensor(0.2812, device='cuda:0')\n",
            "dev_acc: tensor(0.2578, device='cuda:0')\n",
            "epoch: 12\n",
            "train acc: tensor(0.2885, device='cuda:0')\n",
            "dev_acc: tensor(0.2651, device='cuda:0')\n",
            "epoch: 13\n",
            "train acc: tensor(0.2936, device='cuda:0')\n",
            "dev_acc: tensor(0.2688, device='cuda:0')\n",
            "epoch: 14\n",
            "train acc: tensor(0.2989, device='cuda:0')\n",
            "dev_acc: tensor(0.2719, device='cuda:0')\n",
            "epoch: 15\n",
            "train acc: tensor(0.3043, device='cuda:0')\n",
            "dev_acc: tensor(0.2802, device='cuda:0')\n",
            "epoch: 16\n",
            "train acc: tensor(0.3121, device='cuda:0')\n",
            "dev_acc: tensor(0.2807, device='cuda:0')\n",
            "epoch: 17\n",
            "train acc: tensor(0.3161, device='cuda:0')\n",
            "dev_acc: tensor(0.2828, device='cuda:0')\n",
            "epoch: 18\n",
            "train acc: tensor(0.3248, device='cuda:0')\n",
            "dev_acc: tensor(0.2844, device='cuda:0')\n",
            "epoch: 19\n",
            "train acc: tensor(0.3330, device='cuda:0')\n",
            "dev_acc: tensor(0.2885, device='cuda:0')\n",
            "epoch: 20\n",
            "train acc: tensor(0.3385, device='cuda:0')\n",
            "dev_acc: tensor(0.2911, device='cuda:0')\n",
            "epoch: 21\n",
            "train acc: tensor(0.3456, device='cuda:0')\n",
            "dev_acc: tensor(0.2958, device='cuda:0')\n",
            "epoch: 22\n",
            "train acc: tensor(0.3524, device='cuda:0')\n",
            "dev_acc: tensor(0.2969, device='cuda:0')\n",
            "epoch: 23\n",
            "train acc: tensor(0.3574, device='cuda:0')\n",
            "dev_acc: tensor(0.3052, device='cuda:0')\n",
            "epoch: 24\n",
            "train acc: tensor(0.3622, device='cuda:0')\n",
            "dev_acc: tensor(0.3078, device='cuda:0')\n",
            "epoch: 25\n",
            "train acc: tensor(0.3690, device='cuda:0')\n",
            "dev_acc: tensor(0.3151, device='cuda:0')\n",
            "epoch: 26\n",
            "train acc: tensor(0.3739, device='cuda:0')\n",
            "dev_acc: tensor(0.3161, device='cuda:0')\n",
            "epoch: 27\n",
            "train acc: tensor(0.3810, device='cuda:0')\n",
            "dev_acc: tensor(0.3208, device='cuda:0')\n",
            "epoch: 28\n",
            "train acc: tensor(0.3873, device='cuda:0')\n",
            "dev_acc: tensor(0.3234, device='cuda:0')\n",
            "epoch: 29\n",
            "train acc: tensor(0.3939, device='cuda:0')\n",
            "dev_acc: tensor(0.3260, device='cuda:0')\n",
            "epoch: 30\n",
            "train acc: tensor(0.3998, device='cuda:0')\n",
            "dev_acc: tensor(0.3281, device='cuda:0')\n",
            "epoch: 31\n",
            "train acc: tensor(0.4051, device='cuda:0')\n",
            "dev_acc: tensor(0.3333, device='cuda:0')\n",
            "epoch: 32\n",
            "train acc: tensor(0.4101, device='cuda:0')\n",
            "dev_acc: tensor(0.3427, device='cuda:0')\n",
            "epoch: 33\n",
            "train acc: tensor(0.4139, device='cuda:0')\n",
            "dev_acc: tensor(0.3417, device='cuda:0')\n",
            "epoch: 34\n",
            "train acc: tensor(0.4179, device='cuda:0')\n",
            "dev_acc: tensor(0.3453, device='cuda:0')\n",
            "epoch: 35\n",
            "train acc: tensor(0.4239, device='cuda:0')\n",
            "dev_acc: tensor(0.3495, device='cuda:0')\n",
            "epoch: 36\n",
            "train acc: tensor(0.4286, device='cuda:0')\n",
            "dev_acc: tensor(0.3505, device='cuda:0')\n",
            "epoch: 37\n",
            "train acc: tensor(0.4326, device='cuda:0')\n",
            "dev_acc: tensor(0.3521, device='cuda:0')\n",
            "epoch: 38\n",
            "train acc: tensor(0.4367, device='cuda:0')\n",
            "dev_acc: tensor(0.3542, device='cuda:0')\n",
            "epoch: 39\n",
            "train acc: tensor(0.4396, device='cuda:0')\n",
            "dev_acc: tensor(0.3578, device='cuda:0')\n",
            "epoch: 40\n",
            "train acc: tensor(0.4433, device='cuda:0')\n",
            "dev_acc: tensor(0.3641, device='cuda:0')\n",
            "epoch: 41\n",
            "train acc: tensor(0.4460, device='cuda:0')\n",
            "dev_acc: tensor(0.3641, device='cuda:0')\n",
            "epoch: 42\n",
            "train acc: tensor(0.4499, device='cuda:0')\n",
            "dev_acc: tensor(0.3688, device='cuda:0')\n",
            "epoch: 43\n",
            "train acc: tensor(0.4535, device='cuda:0')\n",
            "dev_acc: tensor(0.3781, device='cuda:0')\n",
            "epoch: 44\n",
            "train acc: tensor(0.4566, device='cuda:0')\n",
            "dev_acc: tensor(0.3792, device='cuda:0')\n",
            "epoch: 45\n",
            "train acc: tensor(0.4616, device='cuda:0')\n",
            "dev_acc: tensor(0.3833, device='cuda:0')\n",
            "epoch: 46\n",
            "train acc: tensor(0.4658, device='cuda:0')\n",
            "dev_acc: tensor(0.3875, device='cuda:0')\n",
            "epoch: 47\n",
            "train acc: tensor(0.4701, device='cuda:0')\n",
            "dev_acc: tensor(0.3917, device='cuda:0')\n",
            "epoch: 48\n",
            "train acc: tensor(0.4743, device='cuda:0')\n",
            "dev_acc: tensor(0.3943, device='cuda:0')\n",
            "epoch: 49\n",
            "train acc: tensor(0.4793, device='cuda:0')\n",
            "dev_acc: tensor(0.3969, device='cuda:0')\n",
            "epoch: 50\n",
            "train acc: tensor(0.4836, device='cuda:0')\n",
            "dev_acc: tensor(0.3969, device='cuda:0')\n",
            "epoch: 51\n",
            "train acc: tensor(0.4854, device='cuda:0')\n",
            "dev_acc: tensor(0.4042, device='cuda:0')\n",
            "epoch: 52\n",
            "train acc: tensor(0.4887, device='cuda:0')\n",
            "dev_acc: tensor(0.4016, device='cuda:0')\n",
            "epoch: 53\n",
            "train acc: tensor(0.4922, device='cuda:0')\n",
            "dev_acc: tensor(0.4036, device='cuda:0')\n",
            "epoch: 54\n",
            "train acc: tensor(0.4958, device='cuda:0')\n",
            "dev_acc: tensor(0.4052, device='cuda:0')\n",
            "epoch: 55\n",
            "train acc: tensor(0.4981, device='cuda:0')\n",
            "dev_acc: tensor(0.4089, device='cuda:0')\n",
            "epoch: 56\n",
            "train acc: tensor(0.5026, device='cuda:0')\n",
            "dev_acc: tensor(0.4094, device='cuda:0')\n",
            "epoch: 57\n",
            "train acc: tensor(0.5069, device='cuda:0')\n",
            "dev_acc: tensor(0.4109, device='cuda:0')\n",
            "epoch: 58\n",
            "train acc: tensor(0.5103, device='cuda:0')\n",
            "dev_acc: tensor(0.4125, device='cuda:0')\n",
            "epoch: 59\n",
            "train acc: tensor(0.5123, device='cuda:0')\n",
            "dev_acc: tensor(0.4135, device='cuda:0')\n",
            "epoch: 60\n",
            "train acc: tensor(0.5143, device='cuda:0')\n",
            "dev_acc: tensor(0.4151, device='cuda:0')\n",
            "epoch: 61\n",
            "train acc: tensor(0.5191, device='cuda:0')\n",
            "dev_acc: tensor(0.4172, device='cuda:0')\n",
            "epoch: 62\n",
            "train acc: tensor(0.5218, device='cuda:0')\n",
            "dev_acc: tensor(0.4151, device='cuda:0')\n",
            "epoch: 63\n",
            "train acc: tensor(0.5253, device='cuda:0')\n",
            "dev_acc: tensor(0.4193, device='cuda:0')\n",
            "epoch: 64\n",
            "train acc: tensor(0.5275, device='cuda:0')\n",
            "dev_acc: tensor(0.4193, device='cuda:0')\n",
            "epoch: 65\n",
            "train acc: tensor(0.5315, device='cuda:0')\n",
            "dev_acc: tensor(0.4214, device='cuda:0')\n",
            "epoch: 66\n",
            "train acc: tensor(0.5331, device='cuda:0')\n",
            "dev_acc: tensor(0.4219, device='cuda:0')\n",
            "epoch: 67\n",
            "train acc: tensor(0.5381, device='cuda:0')\n",
            "dev_acc: tensor(0.4266, device='cuda:0')\n",
            "epoch: 68\n",
            "train acc: tensor(0.5416, device='cuda:0')\n",
            "dev_acc: tensor(0.4271, device='cuda:0')\n",
            "epoch: 69\n",
            "train acc: tensor(0.5474, device='cuda:0')\n",
            "dev_acc: tensor(0.4271, device='cuda:0')\n",
            "epoch: 70\n",
            "train acc: tensor(0.5508, device='cuda:0')\n",
            "dev_acc: tensor(0.4307, device='cuda:0')\n",
            "epoch: 71\n",
            "train acc: tensor(0.5547, device='cuda:0')\n",
            "dev_acc: tensor(0.4318, device='cuda:0')\n",
            "epoch: 72\n",
            "train acc: tensor(0.5569, device='cuda:0')\n",
            "dev_acc: tensor(0.4339, device='cuda:0')\n",
            "epoch: 73\n",
            "train acc: tensor(0.5606, device='cuda:0')\n",
            "dev_acc: tensor(0.4365, device='cuda:0')\n",
            "epoch: 74\n",
            "train acc: tensor(0.5632, device='cuda:0')\n",
            "dev_acc: tensor(0.4339, device='cuda:0')\n",
            "epoch: 75\n",
            "train acc: tensor(0.5674, device='cuda:0')\n",
            "dev_acc: tensor(0.4339, device='cuda:0')\n",
            "epoch: 76\n",
            "train acc: tensor(0.5677, device='cuda:0')\n",
            "dev_acc: tensor(0.4380, device='cuda:0')\n",
            "epoch: 77\n",
            "train acc: tensor(0.5734, device='cuda:0')\n",
            "dev_acc: tensor(0.4401, device='cuda:0')\n",
            "epoch: 78\n",
            "train acc: tensor(0.5748, device='cuda:0')\n",
            "dev_acc: tensor(0.4396, device='cuda:0')\n",
            "epoch: 79\n",
            "train acc: tensor(0.5780, device='cuda:0')\n",
            "dev_acc: tensor(0.4385, device='cuda:0')\n",
            "epoch: 80\n",
            "train acc: tensor(0.5805, device='cuda:0')\n",
            "dev_acc: tensor(0.4401, device='cuda:0')\n",
            "epoch: 81\n",
            "train acc: tensor(0.5837, device='cuda:0')\n",
            "dev_acc: tensor(0.4406, device='cuda:0')\n",
            "epoch: 82\n",
            "train acc: tensor(0.5878, device='cuda:0')\n",
            "dev_acc: tensor(0.4406, device='cuda:0')\n",
            "epoch: 83\n",
            "train acc: tensor(0.5910, device='cuda:0')\n",
            "dev_acc: tensor(0.4438, device='cuda:0')\n",
            "epoch: 84\n",
            "train acc: tensor(0.5957, device='cuda:0')\n",
            "dev_acc: tensor(0.4385, device='cuda:0')\n",
            "epoch: 85\n",
            "train acc: tensor(0.5979, device='cuda:0')\n",
            "dev_acc: tensor(0.4422, device='cuda:0')\n",
            "epoch: 86\n",
            "train acc: tensor(0.6013, device='cuda:0')\n",
            "dev_acc: tensor(0.4396, device='cuda:0')\n",
            "epoch: 87\n",
            "train acc: tensor(0.6042, device='cuda:0')\n",
            "dev_acc: tensor(0.4391, device='cuda:0')\n",
            "epoch: 88\n",
            "train acc: tensor(0.6074, device='cuda:0')\n",
            "dev_acc: tensor(0.4406, device='cuda:0')\n",
            "epoch: 89\n",
            "train acc: tensor(0.6106, device='cuda:0')\n",
            "dev_acc: tensor(0.4375, device='cuda:0')\n",
            "epoch: 90\n",
            "train acc: tensor(0.6124, device='cuda:0')\n",
            "dev_acc: tensor(0.4370, device='cuda:0')\n",
            "epoch: 91\n",
            "train acc: tensor(0.6137, device='cuda:0')\n",
            "dev_acc: tensor(0.4370, device='cuda:0')\n",
            "epoch: 92\n",
            "train acc: tensor(0.6163, device='cuda:0')\n",
            "dev_acc: tensor(0.4339, device='cuda:0')\n",
            "epoch: 93\n",
            "train acc: tensor(0.6210, device='cuda:0')\n",
            "dev_acc: tensor(0.4349, device='cuda:0')\n",
            "epoch: 94\n",
            "train acc: tensor(0.6224, device='cuda:0')\n",
            "dev_acc: tensor(0.4344, device='cuda:0')\n",
            "epoch: 95\n",
            "train acc: tensor(0.6269, device='cuda:0')\n",
            "dev_acc: tensor(0.4339, device='cuda:0')\n",
            "epoch: 96\n",
            "train acc: tensor(0.6269, device='cuda:0')\n",
            "dev_acc: tensor(0.4323, device='cuda:0')\n",
            "epoch: 97\n",
            "train acc: tensor(0.6325, device='cuda:0')\n",
            "dev_acc: tensor(0.4328, device='cuda:0')\n",
            "epoch: 98\n",
            "train acc: tensor(0.6345, device='cuda:0')\n",
            "dev_acc: tensor(0.4339, device='cuda:0')\n",
            "epoch: 99\n",
            "train acc: tensor(0.6390, device='cuda:0')\n",
            "dev_acc: tensor(0.4349, device='cuda:0')\n",
            "epoch: 100\n",
            "train acc: tensor(0.6413, device='cuda:0')\n",
            "dev_acc: tensor(0.4385, device='cuda:0')\n",
            "epoch: 101\n",
            "train acc: tensor(0.6453, device='cuda:0')\n",
            "dev_acc: tensor(0.4344, device='cuda:0')\n",
            "epoch: 102\n",
            "train acc: tensor(0.6467, device='cuda:0')\n",
            "dev_acc: tensor(0.4323, device='cuda:0')\n",
            "epoch: 103\n",
            "train acc: tensor(0.6506, device='cuda:0')\n",
            "dev_acc: tensor(0.4339, device='cuda:0')\n",
            "epoch: 104\n",
            "train acc: tensor(0.6531, device='cuda:0')\n",
            "dev_acc: tensor(0.4333, device='cuda:0')\n",
            "epoch: 105\n",
            "train acc: tensor(0.6566, device='cuda:0')\n",
            "dev_acc: tensor(0.4318, device='cuda:0')\n",
            "epoch: 106\n",
            "train acc: tensor(0.6589, device='cuda:0')\n",
            "dev_acc: tensor(0.4318, device='cuda:0')\n",
            "epoch: 107\n",
            "train acc: tensor(0.6600, device='cuda:0')\n",
            "dev_acc: tensor(0.4333, device='cuda:0')\n",
            "epoch: 108\n",
            "train acc: tensor(0.6642, device='cuda:0')\n",
            "dev_acc: tensor(0.4318, device='cuda:0')\n",
            "epoch: 109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-81e1a5ec4f60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"UNIK_best_optim.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dev_acc:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-81e1a5ec4f60>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mopti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mcorrect\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35vWxYnGxncv",
        "outputId": "313afe24-c0f7-4f40-d857-53d08f038773"
      },
      "source": [
        "def predict(net,dataloader):\n",
        "    net.eval()\n",
        "    predictions = torch.tensor([]).cuda(gpu)\n",
        "    with torch.no_grad():\n",
        "        for i, (x,y) in enumerate(test_loader):\n",
        "            x,y=x.cuda(gpu),y.cuda(gpu)\n",
        "            logit = net(x)\n",
        "            pred = torch.argmax(logit,dim=1)+1\n",
        "            predictions=torch.cat((predictions,pred))\n",
        "    return predictions.cpu().numpy()\n",
        "pred = predict(net,test_loader)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1. 11.  9. ... 15.  6. 12.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiSrPYEvx2YX"
      },
      "source": [
        "output = pd.read_csv(root_path+\"sample.csv\")\n",
        "output['Category']=pred.astype('int')\n",
        "output.head()\n",
        "output.to_csv(\"predictions.csv\",index=None)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}