{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project1-V3.ipynb","provenance":[],"authorship_tag":"ABX9TyMbEU2u4h8zehXRY7ECP5Uo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"CqproRflACjr","executionInfo":{"status":"ok","timestamp":1630043958957,"user_tz":-600,"elapsed":2927,"user":{"displayName":"Chester Guan","photoUrl":"","userId":"03005640653142023018"}}},"source":["from google.colab import drive \n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import time\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","from torch.utils.data import TensorDataset, DataLoader, Dataset\n","import matplotlib.pyplot as plt\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U5UgQli8AI87","executionInfo":{"status":"ok","timestamp":1630043982127,"user_tz":-600,"elapsed":23171,"user":{"displayName":"Chester Guan","photoUrl":"","userId":"03005640653142023018"}},"outputId":"7eb26c2d-730f-4743-95ee-c593c69e3ac1"},"source":["drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hkUIxqztAJEM","executionInfo":{"status":"ok","timestamp":1630043982127,"user_tz":-600,"elapsed":3,"user":{"displayName":"Chester Guan","photoUrl":"","userId":"03005640653142023018"}}},"source":["def To3DFeatures(array):\n","    new_array = []\n","\n","    for row in array:\n","        frame_list = []\n","        one_frame = []\n","        joint_coordinate = []\n","        for index, item in enumerate(row):\n","          joint_coordinate.append(item)\n","          if index % 3 == 2:\n","            one_frame.append(joint_coordinate)\n","            joint_coordinate = []\n","          if index % 60 == 59:\n","              frame_list.append(one_frame)\n","              one_frame = []\n","        new_array.append(frame_list)\n","    \n","    return new_array\n","\n","def ToMotionFeature(array):\n","    motion_feature = []\n","    \n","    for index1, frame_list in enumerate(array):\n","        frame_motion = []\n","        for index2, frame in enumerate(frame_list):\n","            if index2 > 0:\n","                motion = []\n","                for index3, joint in enumerate(frame):\n","                    \n","                    x_movement = frame_list[index2][index3][0] - frame_list[index2 - 1][index3][0]\n","                    y_movement = frame_list[index2][index3][1] - frame_list[index2 - 1][index3][1]\n","                    z_movement = frame_list[index2][index3][2] - frame_list[index2 - 1][index3][2]\n","                    motion.append([x_movement, y_movement, z_movement])\n","                frame_motion.append(motion)   \n","                \n","                \n","        motion_feature.append(frame_motion)\n","    return torch.FloatTensor(motion_feature)\n","\n","def DataSplit(data, r1 = 5, r2 = 10, split_size = 0.2):\n","  #input: loaded data,\n","  #output: train, validation, test set (np array)\n","  #explanation: remove the first column (id), feature set is the column from 1 - 960, test set is the column 961\n","\n","  features = [i for i in range(1,961)]\n","  labels = [961]\n","  \n","  x_train = data[features]\n","  y_train = data[labels]\n","\n","  x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = split_size, random_state = r1)\n","  x_validation, x_test, y_validation, y_test = train_test_split(x_test, y_test, test_size = 0.5, random_state = r2)\n","\n","\n","  return x_train.values, x_validation.values, x_test.values, y_train.values, y_validation.values, y_test.values\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aoq2YzMXAKkN","executionInfo":{"status":"ok","timestamp":1630044161067,"user_tz":-600,"elapsed":178942,"user":{"displayName":"Chester Guan","photoUrl":"","userId":"03005640653142023018"}}},"source":["train_path = '/content/drive/MyDrive/Project1-Group 46/train.csv'\n","test_path = '/content/drive/MyDrive/Project1-Group 46/test.csv'\n","\n","train_data = pd.read_csv(train_path, header = None)\n","\n","\n","x_train, x_validation, x_test, y_train, y_validation, y_test = DataSplit(train_data)\n","\n","\n","\n","x_train = To3DFeatures(x_train)\n","x_validation = To3DFeatures(x_validation)\n","x_test = To3DFeatures(x_test)\n","\n","\n","\n","x_train = torch.FloatTensor(x_train)\n","x_validation = torch.FloatTensor(x_validation)\n","x_test = torch.FloatTensor(x_test)\n","y_train = torch.LongTensor(y_train)\n","y_validation = torch.LongTensor(y_validation)\n","y_test = torch.LongTensor(y_test)\n","\n","y_train = torch.flatten(y_train)\n","y_validation = torch.flatten(y_validation)\n","y_test = torch.flatten(y_test)\n","\n","\n","\n","x_train_motion = ToMotionFeature(x_train)\n","x_validation_motion = ToMotionFeature(x_validation)\n","x_test_motion = ToMotionFeature(x_test)\n","\n","\n","\n","x_train = np.swapaxes(x_train,1,3)\n","x_validation = np.swapaxes(x_validation,1,3)\n","x_test = np.swapaxes(x_test,1,3)\n","\n","x_train_motion = np.swapaxes(x_train_motion,1,3)\n","x_validation_motion = np.swapaxes(x_validation_motion,1,3)\n","x_test_motion = np.swapaxes(x_test_motion,1,3)\n","\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"YFswPefpAn3b","executionInfo":{"status":"ok","timestamp":1630044161070,"user_tz":-600,"elapsed":5,"user":{"displayName":"Chester Guan","photoUrl":"","userId":"03005640653142023018"}}},"source":["class SKEDataset(Dataset):\n","\n","    def __init__(self, x1_train, x2_train, y_train):\n","\n","        self.x1_train = x1_train\n","        self.x2_train = x2_train\n","\n","        self.y_train = y_train\n","\n","    def __len__(self):\n","        return len(self.x1_train)\n","\n","    def __getitem__(self, index):\n","\n","\n","        return self.x1_train[index], self.x2_train[index], self.y_train[index]\n","\n","\n","train_set = SKEDataset(x_train, x_train_motion, y_train)\n","dev_set = SKEDataset(x_validation, x_validation_motion, y_validation)\n","\n","\n","train_loader = DataLoader(train_set, batch_size = 64)\n","dev_loader = DataLoader(dev_set, batch_size = 64)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q2lINV64A1Ui","executionInfo":{"status":"ok","timestamp":1630044161070,"user_tz":-600,"elapsed":4,"user":{"displayName":"Chester Guan","photoUrl":"","userId":"03005640653142023018"}}},"source":["class CNN2d_x1(nn.Module):\n","  def __init__(self):\n","    super(CNN2d_x1, self).__init__()\n","\n","    #20 * 16 * 3\n","    self.conv1 = nn.Sequential(\n","        nn.Conv2d(in_channels=3, \n","                  out_channels=16, \n","                  kernel_size=3, \n","                  stride = 1,\n","                  padding = 1\n","        ),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size = 2,stride = 2)\n","    )\n","\n","    #16 * 10 * 8  \n","\n","\n","  def forward(self, x):\n","    x = self.conv1(x)\n","\n","    return x\n","\n","\n","class CNN2d_x2(nn.Module):\n","  def __init__(self):\n","    super(CNN2d_x2, self).__init__()\n","\n","    # 3 * 20 * 15\n","    self.conv1 = nn.Sequential(\n","        nn.Conv2d(in_channels=3, \n","                  out_channels=16, \n","                  kernel_size=3, \n","                  stride = 1,\n","                  padding = 1\n","        ),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size = 2,stride = 2)\n","    )\n","\n","    #16 * 10 * 7 \n","\n","  def forward(self, x):\n","    x = self.conv1(x)\n","\n","    return x\n","\n","class Ensemble(nn.Module):\n","    def __init__(self, modelA, modelB):\n","        super(Ensemble, self).__init__()\n","    \n","        self.modelA = modelA\n","        self.modelB = modelB\n","        \n","        self.fc1 = nn.Linear(16 * 10 * 15, 50)\n","    \n","    \n","        #16 * 10 * 7 \n","    \n","    def forward(self, x1, x2):\n","      x1 = self.modelA(x1)\n","      x2 = self.modelB(x2)\n","      \n","      x = torch.cat((x1,x2), dim = 3)\n","      x = x.view(-1, 16 * 10 * 15)\n","      \n","      x = self.fc1(x)\n","      \n","      return F.log_softmax(x, dim=1)\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"IXPsx2PxA1WY","executionInfo":{"status":"ok","timestamp":1630044161071,"user_tz":-600,"elapsed":4,"user":{"displayName":"Chester Guan","photoUrl":"","userId":"03005640653142023018"}}},"source":["\n","def train(model, criterion, opti, train_loader, dev_loader, max_eps):\n","  best_acc = 0\n","  st = time.time()\n","\n","  train_correct = []\n","  dev_correct = []\n","  train_losses = []\n","  dev_losses = []\n","  for ep in range(max_eps):\n","    trn_corr = 0\n","    tst_corr = 0\n","    total_y = 0\n","    count = 0\n","    mean_loss = 0\n","\n","    for b, (x1_train, x2_train, y_train) in enumerate(train_loader):\n","      b += 1\n","      y_pred = model(x1_train, x2_train)\n","      loss = criterion(y_pred, y_train)\n","\n","      predicted = torch.max(y_pred.data, 1)[1]\n","      batch_corr = (predicted == y_train).sum()\n","      trn_corr += batch_corr\n","\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","      if b % 30 == 0:\n","        print((\"Iteration {} of epoch {} complete. Loss: {}; Acc =: {}, Time taken (s): {}\".format(b, ep, loss.item(), batch_corr/len(y_train), (time.time()-st))))\n","    \n","\n","    with torch.no_grad():\n","      for b,(x1_dev, x2_dev, y_dev) in enumerate(dev_loader):\n","        y_val = model(x1_dev, x2_dev)\n","        predicted = torch.max(y_val.data,1)[1]\n","        tst_corr += (predicted == y_dev).sum()\n","        total_y += len(predicted)\n","        count += 1\n","\n","        mean_loss += criterion(y_val, y_dev)\n","    \n","    acc_dev = tst_corr / total_y\n","    mean_loss = mean_loss / count\n","\n","    print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {}\".format(ep, acc_dev, mean_loss))\n","    if acc_dev > best_acc:\n","        print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, acc_dev))\n","        best_acc = acc_dev\n","        torch.save(model.state_dict(), 'sstcls_{}.dat'.format(ep))\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLbRI4swA1YQ"},"source":["model_a = CNN2d_x1()\n","model_b = CNN2d_x2()\n","\n","ensemble_model = Ensemble(model_a, model_b)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(ensemble_model.parameters(), lr = 0.01)\n","max_eps = 100\n","train(ensemble_model, criterion, optimizer, train_loader, dev_loader, max_eps)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQCHXCrJA1b6","executionInfo":{"status":"ok","timestamp":1630044826297,"user_tz":-600,"elapsed":268,"user":{"displayName":"Chester Guan","photoUrl":"","userId":"03005640653142023018"}}},"source":["pre_model_a = CNN2d_x1()\n","pre_model_b = CNN2d_x2()\n","\n","predict_model = Ensemble(pre_model_a, pre_model_b)\n","predict_model.load_state_dict(torch.load('sstcls_53.dat'))\n","\n","with torch.no_grad():\n","  y_eval = predict_model.forward(x_test, x_test_motion)\n","  loss = criterion(y_eval, y_test)\n","  prediction = torch.max(y_eval.data,1)[1]"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqwZ1gwiA1eT","executionInfo":{"status":"ok","timestamp":1630044828364,"user_tz":-600,"elapsed":357,"user":{"displayName":"Chester Guan","photoUrl":"","userId":"03005640653142023018"}},"outputId":"3256a327-f1cb-4470-e7de-0a3fa4a1292f"},"source":["accuracy_score(y_test, prediction)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.3588924387646432"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"CZ8_JG3KMYRa"},"source":[""],"execution_count":null,"outputs":[]}]}