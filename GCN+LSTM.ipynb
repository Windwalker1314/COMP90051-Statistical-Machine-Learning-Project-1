{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GCN+LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tb4cBqe2EFb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCUIHWoO7PQG",
        "outputId": "e90c5dcf-c09a-4245-fcf4-1e5a93b926af"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMzR5L022tPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef5574c-320d-4b79-c437-b3c5f2a09f2d"
      },
      "source": [
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 8.0 MB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 376 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.1 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiowiwejmz_5"
      },
      "source": [
        "gpu=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA6rx8cPzTGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57004e7f-3cf6-4d31-9a19-1f7590acbc04"
      },
      "source": [
        "edge_list = np.array([(4,3),(3,5),(5,6),(6,7),(7,8),(3,9),(9,10),\n",
        "                 (10,11),(11,12),(3,2),(2,1),(1,13),(1,17),\n",
        "                 (13,14),(14,15),(15,16),(17,18),(18,19),\n",
        "                 (19,20)]) - 1\n",
        "l1,l2 = [],[]\n",
        "for i,j in edge_list:\n",
        "    l1.append(i)\n",
        "    l1.append(j)\n",
        "    l2.append(j)\n",
        "    l2.append(i)\n",
        "\n",
        "edge_index = torch.tensor([l1,l2], dtype=torch.long)\n",
        "if gpu is not None:\n",
        "    edge_index = edge_index.cuda(gpu)\n",
        "print(edge_index.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 38])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVInjE-b-ym_"
      },
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "def bn_init(bn, scale):\n",
        "    nn.init.constant_(bn.weight, scale)\n",
        "    nn.init.constant_(bn.bias, 0)\n",
        "\n",
        "class gcn(nn.Module):\n",
        "    def __init__(self, in_C, out_C):\n",
        "        super(gcn,self).__init__()\n",
        "        self.in_C = in_C\n",
        "        self.bn = nn.BatchNorm1d(in_C)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.conv1 = GCNConv(in_C, 32)\n",
        "        self.conv2 = GCNConv(32, 64)\n",
        "        self.conv3 = GCNConv(64, out_C)\n",
        "    def forward(self, x, edges):\n",
        "        # input  N  V  C_in\n",
        "        # output N  V*C_out\n",
        "        # Batch normalization\n",
        "        N, V, C = x.size()\n",
        "        x = x.permute(0,2,1).contiguous().view(N,C,V)\n",
        "        x = self.bn(x)\n",
        "        x = x.permute(0,2,1).contiguous().view(N, V, C)\n",
        "\n",
        "        # Graph convolution with residual\n",
        "        x = self.conv1(x, edges)\n",
        "        x = F.relu(x)\n",
        "        #residual = x\n",
        "\n",
        "        x = self.conv2(x, edges)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x, edges)\n",
        "        x = F.relu(x)\n",
        "        #x = x + residual\n",
        "\n",
        "        N, V, C = x.size()\n",
        "        x = x.view(N, V*C).contiguous()\n",
        "        return self.dropout(x)\n",
        "\n",
        "class gcn_LSTM(nn.Module):\n",
        "    def __init__(self, gcn_in_C, n_classes,  gcn_out_C=64, lstm_C=256, lstm_n_layer=2, T=16, V=20):\n",
        "        super(gcn_LSTM, self).__init__()\n",
        "        # input N, T, V, C\n",
        "        # output N, n_classes\n",
        "        self.T = T\n",
        "        self.V = V\n",
        "        self.gcn_layers=nn.ModuleList([gcn(gcn_in_C, gcn_out_C) for i in range(T)])\n",
        "        #self.gcn_layer = gcn(gcn_in_C, gcn_out_C)\n",
        "        self.lstm1 = nn.LSTM(gcn_out_C*V, lstm_C, lstm_n_layer, batch_first=True)\n",
        "        self.classifier = nn.Linear(lstm_C, n_classes)\n",
        "\n",
        "    def forward(self, x, edges):\n",
        "        N, T, V, C = x.size()\n",
        "        assert V==self.V\n",
        "        assert T==self.T\n",
        "\n",
        "        output = torch.tensor([])\n",
        "        if gpu is not None:\n",
        "            output = output.cuda(gpu)\n",
        "        for i in range(T):\n",
        "            output_t = self.gcn_layers[i](x[:, i, :, :],edges)\n",
        "            #output_t = self.gcn_layer(x[:, i, :, :],edges)\n",
        "            output_t = output_t.unsqueeze(1)\n",
        "            if gpu is not None:\n",
        "                output_t = output_t.cuda(gpu)\n",
        "            output = torch.cat((output, output_t ), 1)\n",
        "        output, (ht,ct)= self.lstm1(output)\n",
        "\n",
        "        output = self.classifier(ht[-1])\n",
        "\n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbJtPT3M-X3E"
      },
      "source": [
        "def random_manipulateX(x):\n",
        "    # T,V,C\n",
        "    x[:,:,0] += (torch.rand(1)-0.5)*10\n",
        "    x[:,:,1] += (torch.rand(1)-0.5)*10\n",
        "    x[:,:,2] += (torch.rand(1)-0.5)*10\n",
        "    flip_x, flip_y, flip_z = torch.rand(1)>0.5, torch.rand(1)>0.5,torch.rand(1)>0.5\n",
        "    if flip_x:\n",
        "        x[:,:,0] = -x[:,:,0]\n",
        "    if flip_y:\n",
        "        x[:,:,1] = -x[:,:,1]\n",
        "    if flip_z:\n",
        "        x[:,:,2] = -x[:,:,2]\n",
        "    return x\n",
        "\n",
        "class GCNDataset(Dataset):\n",
        "    def __init__(self,filename,hasLabel=True,aug = False,balance = 0,frac=1):\n",
        "        self.df = pd.read_csv(filename,header=None)\n",
        "        self.length = len(self.df)\n",
        "        self.aug=aug\n",
        "        if hasLabel:\n",
        "            if balance>0:\n",
        "                self.df['freq']=self.df.groupby(961)[961].transform('count')\n",
        "                self.df['freq'] = sum(self.df['freq'])/(self.df['freq']**balance)\n",
        "                self.df = self.df.sample(frac=frac,weights=self.df.freq,replace=False).reset_index(drop=True)\n",
        "                self.X = torch.tensor(self.df.iloc[:,1:-2].values.astype('float32'))\n",
        "                self.labels = self.df.iloc[:,-2].values.astype('int32')-1\n",
        "            else:\n",
        "                self.df = self.df.sample(frac=frac,replace=False).reset_index(drop=True)\n",
        "                self.X = torch.tensor(self.df.iloc[:,1:-1].values.astype('float32'))\n",
        "                self.labels = self.df.iloc[:,-1].values.astype('int32')-1\n",
        "            # N, C, V, T\n",
        "            #self.X = self.X.reshape((self.length ,16, 20, 3)).permute(0,3,2,1).contiguous()\n",
        "            # N, T, V, C\n",
        "            self.X = self.X.reshape((int(self.length*frac) ,16, 20, 3)).contiguous()\n",
        "            self.Y = torch.tensor(self.labels,dtype=torch.long)\n",
        "        else:\n",
        "            self.X = torch.tensor(self.df.iloc[:,1:].values.astype('float32'))\n",
        "            self.X = self.X.reshape((self.length ,16, 20, 3)).contiguous()\n",
        "            self.Y=torch.tensor(np.zeros(self.length),dtype=torch.long)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self,index):\n",
        "        x = self.X[index]\n",
        "        if self.aug:\n",
        "            x = random_manipulateX(x)\n",
        "        y = self.Y[index]\n",
        "        return x, y "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpoViM0N-eiq"
      },
      "source": [
        "root_path = \"drive/MyDrive/SML/\"\n",
        "bs = 64\n",
        "train_set = GCNDataset(filename=root_path+\"training_set.csv\",aug=False)\n",
        "val_set = GCNDataset(filename=root_path+\"val_set.csv\")\n",
        "test_set = GCNDataset(filename=root_path+\"test.csv\",hasLabel=False)\n",
        "train_loader = DataLoader(train_set,batch_size=bs,shuffle=True)\n",
        "val_loader = DataLoader(val_set,batch_size=bs)\n",
        "test_loader = DataLoader(test_set,batch_size=bs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sQjwjOp-mUA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80bcf8b3-760f-415e-b057-7f43100fcc54"
      },
      "source": [
        "net = gcn_LSTM(3,49)\n",
        "#net.load_state_dict(torch.load(root_path+'gcn_LSTM_best.pkl'))\n",
        "\n",
        "gpu = 0 #gpu ID\n",
        "net.cuda(gpu)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "opti = optim.Adam(net.parameters(), lr = 0.001,weight_decay=0.0005)\n",
        "#opti.load_state_dict(torch.load(root_path+'gcn_LSTM_best_optim.pkl'))\n",
        "\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnSl-Z0gZXGk",
        "outputId": "80ca46ec-92cc-4c29-9a98-5445945d5d70"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "count_parameters(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2216337"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpOotKe1Y_dx",
        "outputId": "09560c77-036c-4913-9ffb-fcb04d67bac6"
      },
      "source": [
        "net"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gcn_LSTM(\n",
              "  (gcn_layers): ModuleList(\n",
              "    (0): gcn(\n",
              "      (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (conv1): GCNConv(3, 32)\n",
              "      (conv2): GCNConv(32, 64)\n",
              "      (conv3): GCNConv(64, 64)\n",
              "    )\n",
              "    (1): gcn(\n",
              "      (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (conv1): GCNConv(3, 32)\n",
              "      (conv2): GCNConv(32, 64)\n",
              "      (conv3): GCNConv(64, 64)\n",
              "    )\n",
              "    (2): gcn(\n",
              "      (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (conv1): GCNConv(3, 32)\n",
              "      (conv2): GCNConv(32, 64)\n",
              "      (conv3): GCNConv(64, 64)\n",
              "    )\n",
              "    (3): gcn(\n",
              "      (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (conv1): GCNConv(3, 32)\n",
              "      (conv2): GCNConv(32, 64)\n",
              "      (conv3): GCNConv(64, 64)\n",
              "    )\n",
              "    (4): gcn(\n",
              "      (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (conv1): GCNConv(3, 32)\n",
              "      (conv2): GCNConv(32, 64)\n",
              "      (conv3): GCNConv(64, 64)\n",
              "    )\n",
              "    (5): gcn(\n",
              "      (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (conv1): GCNConv(3, 32)\n",
              "      (conv2): GCNConv(32, 64)\n",
              "      (conv3): GCNConv(64, 64)\n",
              "    )\n",
              "    (6): gcn(\n",
              "      (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (conv1): GCNConv(3, 32)\n",
              "      (conv2): GCNConv(32, 64)\n",
              "      (conv3): GCNConv(64, 64)\n",
              "    )\n",
              "    (7): gcn(\n",
              "      (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (conv1): GCNConv(3, 32)\n",
              "      (conv2): GCNConv(32, 64)\n",
              "      (conv3): GCNConv(64, 64)\n",
              "    )\n",
              "    (8): gcn(\n",
              "      (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (conv1): GCNConv(3, 32)\n",
              "      (conv2): GCNConv(32, 64)\n",
              "      (conv3): GCNConv(64, 64)\n",
              "    )\n",
              "    (9): gcn(\n",
              "      (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (conv1): GCNConv(3, 32)\n",
              "      (conv2): GCNConv(32, 64)\n",
              "      (conv3): GCNConv(64, 64)\n",
              "    )\n",
              "    (10): gcn(\n",
              "      (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (conv1): GCNConv(3, 32)\n",
              "      (conv2): GCNConv(32, 64)\n",
              "      (conv3): GCNConv(64, 64)\n",
              "    )\n",
              "    (11): gcn(\n",
              "      (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (conv1): GCNConv(3, 32)\n",
              "      (conv2): GCNConv(32, 64)\n",
              "      (conv3): GCNConv(64, 64)\n",
              "    )\n",
              "    (12): gcn(\n",
              "      (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (conv1): GCNConv(3, 32)\n",
              "      (conv2): GCNConv(32, 64)\n",
              "      (conv3): GCNConv(64, 64)\n",
              "    )\n",
              "    (13): gcn(\n",
              "      (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (conv1): GCNConv(3, 32)\n",
              "      (conv2): GCNConv(32, 64)\n",
              "      (conv3): GCNConv(64, 64)\n",
              "    )\n",
              "    (14): gcn(\n",
              "      (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (conv1): GCNConv(3, 32)\n",
              "      (conv2): GCNConv(32, 64)\n",
              "      (conv3): GCNConv(64, 64)\n",
              "    )\n",
              "    (15): gcn(\n",
              "      (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (conv1): GCNConv(3, 32)\n",
              "      (conv2): GCNConv(32, 64)\n",
              "      (conv3): GCNConv(64, 64)\n",
              "    )\n",
              "  )\n",
              "  (lstm1): LSTM(1280, 256, num_layers=2, batch_first=True)\n",
              "  (classifier): Linear(in_features=256, out_features=49, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ykzds-iq0o86",
        "outputId": "bff0302e-839f-4ed3-9f0f-8981a8e60a7c"
      },
      "source": [
        "def adjust_learning_rate(lr,wd=0.001):\n",
        "    for param_group in opti.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "        param_group['weight_decay']=wd\n",
        "    return lr\n",
        "\n",
        "def accuracy(logit,target):\n",
        "    a=(torch.argmax(logit,dim=1)==target).sum()\n",
        "    return a\n",
        "\n",
        "def evaluate(model, criterion, dataloader, gpu):\n",
        "    model.eval()\n",
        "    acc = 0\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for i,(x,y) in enumerate(dataloader):\n",
        "            x,y = x.cuda(gpu), y.cuda(gpu)\n",
        "            logits = model(x, edge_index)\n",
        "            acc+= accuracy(logits, y)\n",
        "            count += bs\n",
        "\n",
        "    return acc / count\n",
        "\n",
        "def train():\n",
        "    best_acc=0.415\n",
        "    best_epoch = 0\n",
        "    for epoch in range(150):\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        \"\"\"\n",
        "        if epoch==0:\n",
        "            adjust_learning_rate(0.01)\n",
        "        elif epoch==50:\n",
        "            adjust_learning_rate(0.001)\n",
        "        elif epoch==120:\n",
        "            adjust_learning_rate(0.0001)\n",
        "        elif epoch==140:\n",
        "            adjust_learning_rate(0.00001)\n",
        "        \"\"\"\n",
        "        for i, (x,y) in enumerate(train_loader):\n",
        "            net.train()\n",
        "            opti.zero_grad()\n",
        "            x,y=x.cuda(gpu),y.cuda(gpu)\n",
        "            opti.zero_grad()\n",
        "            logit = net(x,edge_index)\n",
        "            loss = criterion(logit,y)\n",
        "            loss.backward()\n",
        "            opti.step()\n",
        "            correct+=accuracy(logit,y)\n",
        "            total+=bs\n",
        "\n",
        "        dev_acc = evaluate(net, criterion, val_loader, gpu)\n",
        "        if dev_acc>best_acc+0.003:\n",
        "            best_acc=dev_acc\n",
        "            torch.save(net.state_dict(), root_path+'gcn_LSTM_best.pkl')\n",
        "            torch.save(opti.state_dict(), root_path+\"gcn_LSTM_best_optim.pkl\")\n",
        "        print(\"epoch\",epoch,\"train acc:\",round(float(correct/total),5),\"dev_acc:\",round(float(dev_acc),5))\n",
        "train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 train acc: 0.15704 dev_acc: 0.2276\n",
            "epoch 1 train acc: 0.24656 dev_acc: 0.26146\n",
            "epoch 2 train acc: 0.29237 dev_acc: 0.30365\n",
            "epoch 3 train acc: 0.32693 dev_acc: 0.31458\n",
            "epoch 4 train acc: 0.34931 dev_acc: 0.33333\n",
            "epoch 5 train acc: 0.36361 dev_acc: 0.33594\n",
            "epoch 6 train acc: 0.37248 dev_acc: 0.3599\n",
            "epoch 7 train acc: 0.3795 dev_acc: 0.36615\n",
            "epoch 8 train acc: 0.39314 dev_acc: 0.36354\n",
            "epoch 9 train acc: 0.39897 dev_acc: 0.38698\n",
            "epoch 10 train acc: 0.40307 dev_acc: 0.37708\n",
            "epoch 11 train acc: 0.41327 dev_acc: 0.38594\n",
            "epoch 12 train acc: 0.42624 dev_acc: 0.39167\n",
            "epoch 13 train acc: 0.43988 dev_acc: 0.40052\n",
            "epoch 14 train acc: 0.42797 dev_acc: 0.38594\n",
            "epoch 15 train acc: 0.44147 dev_acc: 0.39844\n",
            "epoch 16 train acc: 0.4465 dev_acc: 0.39948\n",
            "epoch 17 train acc: 0.45445 dev_acc: 0.40365\n",
            "epoch 18 train acc: 0.45339 dev_acc: 0.39948\n",
            "epoch 19 train acc: 0.45379 dev_acc: 0.40313\n",
            "epoch 20 train acc: 0.47378 dev_acc: 0.39271\n",
            "epoch 21 train acc: 0.47259 dev_acc: 0.41042\n",
            "epoch 22 train acc: 0.47484 dev_acc: 0.40677\n",
            "epoch 23 train acc: 0.49245 dev_acc: 0.41302\n",
            "epoch 24 train acc: 0.4951 dev_acc: 0.42083\n",
            "epoch 25 train acc: 0.49881 dev_acc: 0.41042\n",
            "epoch 26 train acc: 0.50662 dev_acc: 0.41927\n",
            "epoch 27 train acc: 0.51496 dev_acc: 0.40781\n",
            "epoch 28 train acc: 0.52185 dev_acc: 0.41875\n",
            "epoch 29 train acc: 0.52542 dev_acc: 0.41823\n",
            "epoch 30 train acc: 0.53787 dev_acc: 0.43438\n",
            "epoch 31 train acc: 0.53999 dev_acc: 0.42083\n",
            "epoch 32 train acc: 0.54582 dev_acc: 0.425\n",
            "epoch 33 train acc: 0.55707 dev_acc: 0.4349\n",
            "epoch 34 train acc: 0.55773 dev_acc: 0.43281\n",
            "epoch 35 train acc: 0.56899 dev_acc: 0.41823\n",
            "epoch 36 train acc: 0.57601 dev_acc: 0.42604\n",
            "epoch 37 train acc: 0.58329 dev_acc: 0.41771\n",
            "epoch 38 train acc: 0.58898 dev_acc: 0.41302\n",
            "epoch 39 train acc: 0.59335 dev_acc: 0.43438\n",
            "epoch 40 train acc: 0.6005 dev_acc: 0.42135\n",
            "epoch 41 train acc: 0.61441 dev_acc: 0.42344\n",
            "epoch 42 train acc: 0.61467 dev_acc: 0.41667\n",
            "epoch 43 train acc: 0.63427 dev_acc: 0.44115\n",
            "epoch 44 train acc: 0.63705 dev_acc: 0.43698\n",
            "epoch 45 train acc: 0.64367 dev_acc: 0.40573\n",
            "epoch 46 train acc: 0.64062 dev_acc: 0.41146\n",
            "epoch 47 train acc: 0.66062 dev_acc: 0.42552\n",
            "epoch 48 train acc: 0.66221 dev_acc: 0.42448\n",
            "epoch 49 train acc: 0.66274 dev_acc: 0.41823\n",
            "epoch 50 train acc: 0.68022 dev_acc: 0.42448\n",
            "epoch 51 train acc: 0.68896 dev_acc: 0.42865\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-4704d029a307>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"gcn_LSTM_best_optim.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train acc:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"dev_acc:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-4704d029a307>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mopti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-f9ac070f0fd7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edges)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0moutput_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0;31m#output_t = self.gcn_layer(x[:, i, :, :],edges)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0moutput_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-f9ac070f0fd7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edges)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#x = x + residual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDSLV8bB-w7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7249ea4e-3220-4ebb-81a3-22eb58a58fb4"
      },
      "source": [
        "net.load_state_dict(torch.load(root_path+'gcn_LSTM_best.pkl'))\n",
        "def predict(net,dataloader):\n",
        "    net.eval()\n",
        "    predictions = torch.tensor([]).cuda(gpu)\n",
        "    logits = torch.tensor([]).cuda(gpu)\n",
        "    with torch.no_grad():\n",
        "        for i, (x,y) in enumerate(dataloader):\n",
        "            x,y=x.cuda(gpu),y.cuda(gpu)\n",
        "            logit = net(x,edge_index)\n",
        "            logits = torch.cat((logits,logit))\n",
        "            pred = torch.argmax(logit,dim=1)+1\n",
        "            predictions=torch.cat((predictions,pred))\n",
        "    return predictions.cpu().numpy(), logits.cpu().numpy()\n",
        "pred,logits = predict(net,test_loader)\n",
        "print(pred,logits.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18.  3.  9. ...  3.  5. 12.] (2959, 49)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOY3AFuK-xAT"
      },
      "source": [
        "output = pd.read_csv(root_path+\"sample.csv\")\n",
        "output['Category']=pred.astype('int')\n",
        "output.head()\n",
        "output.to_csv(\"predictions.csv\",index=None)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}